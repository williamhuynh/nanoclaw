# Will Huynh - LinkedIn Voice Samples

These are actual posts from Will to match tone, structure, and style.

## Sample 1: Risk/Governance Focus

57% of organisations say navigating AI regulations is now a major risk.

And it makes sense - AI rules are diverging fast across countries, and the pace of change is only accelerating.

The challenge isn't just understanding the latest regulation. The real issue is knowing:

- What AI is actually in production today
- Where the material risks are right now
- Whether the right controls are in place and working
- How this maps back to your industry obligations and risk framework

This is especially critical in financial services, where compliance expectations are significant, real, and enforceable.

Organisations this year should prioritise identifying deployed AI in a central place, assess risk exposure, and align mitigation to industry context.

#AI #RiskManagement #AIGovernance #FinancialServices

---

## Sample 2: Governance Debt

AI adoption is accelerating fast. Governance capacity isn't.

This creates a growing gap - governance debt - where AI use cases scale faster than oversight, accountability, and risk controls can keep up.

As AI becomes more autonomous and embedded into core workflows, organisations face unanswered questions:
- Who owns each AI system in production?
- How are AI risks identified, controlled, and monitored over time?
- Are the right guardrails in place for bias, drift, privacy, and misuse?
- Can decisions be explained and defended?

Status quo governance wasn't built for learning systems operating at scale.

The winners won't just deploy AI quickly - they'll scale risk controls and governance alongside it with portfolio-level visibility, clear accountability, and continuous oversight.

How is your organisation managing governance debt as AI expands?

---

## Sample 3: Operational Insights

One of our biggest learnings implementing AI in operations is this:

SOPs are the backbone of scale.

They create consistency, reduce risk, and keep organisations running efficiently.

But they rarely stay clean.

Over time:
- procedures become bloated
- workarounds emerge
- systems change
- written process drifts from reality

That gap is where profitability leaks.

What's surprised us is how effective agentic AI can be here.

Not as a chatbot, but as an operational layer that can:
- make sense of messy process documentation
- connect it to live workflows and systems
- surface bottlenecks and improvement opportunities

In many ways, it becomes a control panel for how the business actually runs.

But this only works if it's trusted. That means it must be embedded into workflows, integrated securely with core systems, and governed properly.

This is what we're calling Agentic Operations.

Bringing operational logic to the surface, so it can be improved continuously - not just documented.

---

## Sample 4: Repost with Commentary

Good to see NSW releasing a clearer AI Assessment Framework for agencies. Frameworks like this are an important foundation for safe, fair and responsible use of AI.

Where many organisations struggle, though, is moving from guidance to execution. In practice, AI risk assessments often become Excel templates floating around inboxes and shared drives, disconnected from risk appetite, control libraries and existing GRC processes. The result is lots of activity, but no single view of the organisation's AI risk posture.

Our focus has been on private sector organisations scaling AI. That challenge is exactly why we built AI Risk Navigator - a self-service, AI-enabled approach built on Microsoft that adapts risk assessment to organisational context and embeds AI governance into existing processes, rather than creating another parallel checklist.

AI governance is not just about having a framework. It is about operationalising risk management at scale.

---

## Voice Patterns

**Opening Hooks:**
- Stats that challenge assumptions: "57% of organisations say..."
- Pattern observations: "AI adoption is accelerating fast. Governance capacity isn't."
- Key learnings: "One of our biggest learnings..."

**Signal Phrases:**
- "The real issue is..."
- "What's surprised us is..."
- "Where organisations struggle..."
- "This only works if..."
- "That gap is where..."

**Structure:**
- Hook → Context → Insight → Optional CTA
- Professional but not stiff
- Provocative but not sensational
- Evidence-based but opinionated

**Tone:**
- Pragmatic authority
- "We've been in the trenches" credibility
- Challenges conventional thinking
- Focus on execution gaps, not just theory
- Connects to real enterprise problems

**Avoid:**
- Generic AI hype
- Salesy language
- Abstract theory without application
- Jargon without explanation
- Shallow commentary

**CTAs (when used):**
- Genuine questions: "How is your organisation..."
- Not rhetorical, actually curious
- Invite discussion, not sales calls
